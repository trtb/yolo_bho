{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d00934f",
   "metadata": {},
   "source": [
    "# HollywoodHeads\n",
    "\n",
    "In this notebook, we prepare HollywoodHeads data. Preparation essentially consists of transforming the annotations into the format supported by YoloV7 and creating the summary.txt referencing all the images in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b16525",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "- https://www.di.ens.fr/willow/research/headdetection/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ac5c5",
   "metadata": {},
   "source": [
    "## First step: Download\n",
    "\n",
    "In `homemade/`:\n",
    "\n",
    "From the link, download the following file:\n",
    "- HollywoodHeads.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7cdb2e",
   "metadata": {},
   "source": [
    "## Second step: Prepare repository\n",
    "\n",
    "```bash\n",
    "cd homemade/\n",
    "unzip HollywoodHeads.zip\n",
    "cd HollywoodHeads\n",
    "```\n",
    "\n",
    "```bash\n",
    "mkdir images\n",
    "rep=train; mkdir images/$rep; while read -r line; do mv JPEGImages/${line}.jpeg images/${rep}/; done < Splits/${rep}.txt\n",
    "rep=val; mkdir images/$rep; while read -r line; do mv JPEGImages/${line}.jpeg images/${rep}/; done < Splits/${rep}.txt\n",
    "rep=test; mkdir images/$rep; while read -r line; do mv JPEGImages/${line}.jpeg images/${rep}/; done < Splits/${rep}.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8afa8",
   "metadata": {},
   "source": [
    "## Third step: Prepare labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e42939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"homemade/HollywoodHeads\")\n",
    "repositories = ['train', 'val', 'test']\n",
    "\n",
    "path_images = path / 'images'\n",
    "path_annotations = path / 'Annotations'\n",
    "path_splits = path / 'Splits'\n",
    "odgt_format = path / \"annotation_{}.odgt\"\n",
    "\n",
    "path_labels = path / 'labels'\n",
    "path_labels.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5665ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_yolo(input_file, output_file):\n",
    "    root = ET.parse(input_file).getroot()\n",
    "    \n",
    "    width = int(root.find('size').find('width').text)\n",
    "    height = int(root.find('size').find('height').text)\n",
    "    depth = int(root.find('size').find('depth').text)\n",
    "\n",
    "    strings = []\n",
    "    for obj in root.iter('object'):\n",
    "        if len(obj) == 0:\n",
    "            continue\n",
    "        name = obj.find('name').text\n",
    "        assert(name == 'head')\n",
    "        bb = [float(child.text) for child in obj.find('bndbox')] #xmin, ymin, xmax, ymax\n",
    "        \n",
    "        x_center = (bb[0] + bb[2]) / 2\n",
    "        x_size = (bb[2] - bb[0])\n",
    "        y_center = (bb[1] + bb[3]) / 2\n",
    "        y_size = (bb[3] - bb[1])\n",
    "        \n",
    "        if x_size <= 3 or y_size <= 3:\n",
    "            continue\n",
    "            \n",
    "        x_center /= width\n",
    "        x_size /= width\n",
    "        y_center /= height\n",
    "        y_size /= height\n",
    "        \n",
    "        strings.append(\"{} {:.6f} {:.6f} {:.6f} {:.6f}\".format(0, x_center, y_center, x_size, y_size))\n",
    "    \n",
    "    if len(strings) > 0:\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(\"\\n\".join(strings) + \"\\n\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0672dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing homemade/HollywoodHeads/Splits/train.txt:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216719/216719 [00:38<00:00, 5660.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid images: homemade/HollywoodHeads/Annotations/mov_007_121337.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121338.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121339.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121340.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121341.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121342.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121343.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121344.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121345.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121346.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121347.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121348.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121349.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121350.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121351.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121362.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121363.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121364.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121365.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121366.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121367.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121368.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121371.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121372.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_007_121373.xml\n",
      "Processing homemade/HollywoodHeads/Splits/val.txt:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6719/6719 [00:01<00:00, 5832.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid images: homemade/HollywoodHeads/Annotations/mov_016_020655.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_016_040350.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_016_058149.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_016_058159.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_016_058199.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_016_063144.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_016_099344.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_016_143427.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_016_143457.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_016_143477.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_017674.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_017684.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_017694.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_021212.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_055926.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_055936.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_106337.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_106347.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_106357.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_106367.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_120418.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_121874.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_121896.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_122247.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_122257.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_017_131138.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_027097.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_027107.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_027117.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_037396.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_037406.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_037416.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_057688.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_069745.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_076919.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_076933.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_077752.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_077762.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_077772.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_118413.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_118433.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_159440.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_018_159843.xml\n",
      "Processing homemade/HollywoodHeads/Splits/test.txt:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1302/1302 [00:00<00:00, 5867.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid images: homemade/HollywoodHeads/Annotations/mov_019_126546.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_020_189030.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_021_018056.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_021_061252.xml\n",
      "homemade/HollywoodHeads/Annotations/mov_021_164475.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "for rep in repositories:\n",
    "    split_file = path_splits / (rep + \".txt\")\n",
    "    print(\"Processing {}:\".format(split_file))\n",
    "\n",
    "    with open(split_file, 'r') as f:\n",
    "        image_list = f.read().split('\\n')\n",
    "    image_list = list(filter(len, image_list))\n",
    "    \n",
    "    labels = path_labels / rep\n",
    "    labels.mkdir(exist_ok=True)\n",
    "    \n",
    "    images = path_images / rep\n",
    "    \n",
    "    valid_images = []\n",
    "    invalid_images = []\n",
    "    for image_id in tqdm(image_list):\n",
    "        annotation_file = path_annotations / (image_id + \".xml\")\n",
    "        output_file = labels / (image_id + '.txt')\n",
    "        valid = xml_to_yolo(annotation_file, output_file)\n",
    "        if valid:\n",
    "            image_file = images / (image_id + \".jpeg\")\n",
    "            valid_images.append(str(image_file))\n",
    "        else:\n",
    "            invalid_images.append(str(annotation_file))\n",
    "\n",
    "    with open(labels / \"summary.txt\", 'w') as f:\n",
    "        f.write(\"\\n\".join(valid_images) + \"\\n\")\n",
    "\n",
    "    print(\"Invalid images: {}\".format(\"\\n\".join(invalid_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0416c605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
